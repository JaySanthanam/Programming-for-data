{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Sorting_and_cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaySanthanam/Programming-for-data/blob/main/Worksheets/3_Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first. \n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g. \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make \n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly **immutable**, ie changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df_sorted_on_make` *original dataframe, df, will be as it was - unsorted* \n",
        "\n",
        "To **split** columns away from the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score \n",
        "---\n",
        "\n",
        "Read data into variable called **happiness** from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Write a function called **sorted_rank** to display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "outputId": "2dc73ae9-bea5-4a4a-ba14-a83c9615e6bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "def sorted_rank(df):\n",
        "  # add code below to return a series sorted by Happiness Score in ascending order\n",
        "  happiness_score_sort = df.sort_values(by=['Happiness Score'])\n",
        "  return happiness_score_sort\n",
        "\n",
        "# The code below will run and test your code to see if the first row of your series is correct \n",
        "import pandas as pd\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\"\n",
        "happiness = pd.read_excel(url,sheet_name=\"Happiness-Data-2015\") \n",
        "actual = sorted_rank(happiness).index[0]\n",
        "expected = 157\n",
        "print(sorted_rank(happiness)['Happiness Score'].head())\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157    2.839\n",
            "156    2.905\n",
            "155    3.006\n",
            "154    3.340\n",
            "153    3.465\n",
            "Name: Happiness Score, dtype: float64\n",
            "Well done, test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
        "---\n",
        "\n",
        "Write a function called **get_gdp_health** which:\n",
        "\n",
        "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order \n",
        "2. display the first 5 rows of sorted data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "outputId": "38547a3c-b0f8-4d88-b349-bdcb5a9d1b9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def get_gdp_health(df):\n",
        "  # add code below to return a 5 row series which sorts rows by Economy and Health in ascending order\n",
        "  happiness_sort_twice = df.sort_values(by=['Economy (GDP per Capita)', 'Health (Life Expectancy)'])\n",
        "  return happiness_sort_twice\n",
        "\n",
        "# The code below will run and test your code to see if the first row of your series has the correct happiness score \n",
        "test = get_gdp_health(happiness)\n",
        "\n",
        "actual = test['Happiness Score'].iloc[0]\n",
        "expected = 4.517\n",
        "print(test.head())\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Country              Region  ...  Generosity  Dystopia Residual\n",
            "119  Congo (Kinshasa)  Sub-Saharan Africa  ...     0.24834            2.86712\n",
            "156           Burundi  Sub-Saharan Africa  ...     0.19727            1.83302\n",
            "130            Malawi  Sub-Saharan Africa  ...     0.33128            2.80791\n",
            "143             Niger  Sub-Saharan Africa  ...     0.19387            1.87877\n",
            "115           Liberia  Sub-Saharan Africa  ...     0.24362            2.77729\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "Well done, test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order \n",
        "---\n",
        "\n",
        "Write a function called **get_descending** which will: \n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "outputId": "00bfda4b-2fcb-4b06-e20d-d7065e27ec96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def get_descending(df):\n",
        "  #add code below to return a series which contains the last 5 rows of Country and Region sorted by Freedom and Trust in descending order\n",
        "  happiness_sort_descend = df.sort_values(by=['Freedom','Trust (Government Corruption)'], ascending=False).tail()\n",
        "  return happiness_sort_descend\n",
        "\n",
        "# The code below will run and test your code to see if the length and series are correct \n",
        "actual = get_descending(happiness).index[0]\n",
        "expected = 136\n",
        "if actual == expected and (len(get_descending(happiness)) == 5):\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 5 but was\", len(get_descending(happiness)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values \n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"column\"].isnull().values.any()`  \n",
        "\n",
        "* filter for non-null rows   \n",
        "  `df[~df[\"column\"].isnull()]`  \n",
        "  *hint: ~ means is not*\n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values \n",
        "---\n",
        "\n",
        "1. read data into a variable called **housing** from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv \n",
        "\n",
        "Write a function called **check_null** which will:\n",
        "2. check if any NA values exist in the dataframe and print the result \n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "outputId": "d38e8f10-1ab0-435f-e50d-daa5f3d1406d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def check_null(df):\n",
        "  # add code below to return a bool statement for whether or not there are null values\n",
        "  check_for_null = df.isnull().values.any()\n",
        "  total_null_number = df.isnull().values.any().sum() #to find how many null values there are in the data\n",
        "  print(total_null_number)\n",
        "  return check_for_null\n",
        "\n",
        "# The code below will run and test your code to see if you are returning the correct answer\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "housing = pd.read_csv(url)\n",
        "actual = check_null(housing)\n",
        "expected = True\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "True\n",
            "Test passed True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTecutIXFJM"
      },
      "source": [
        "### Exercise 5 - filter for non-null rows\n",
        "---\n",
        "\n",
        "Create function called **filter_null()** which filters the non-null rows by the `number_of_jobs` column. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fWi0_MLXEzY",
        "outputId": "fe8615e4-c348-4299-dd22-8048788dbc0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def filter_null(df):\n",
        "  # add code below to filter out null values\n",
        "  filter_out_null = df[df.number_of_jobs.notnull()]\n",
        "  return filter_out_null\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the length of your returned dataframe is correct\n",
        "\n",
        "actual = len(filter_null(housing))\n",
        "expected = 931 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed expected\", expected, \"got\", actual)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values \n",
        "---\n",
        "Write a function called **drop_null** which will:\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK",
        "outputId": "21809396-6384-4b01-e107-f26b1fc2c822",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def drop_null(df):\n",
        "  # add code which returns a dataframe with rows that contain NA values in the life_satisfaction column removed\n",
        "  housing_drop_null_life_satisfaction = df.dropna(subset = [\"life_satisfaction\"])\n",
        "  return housing_drop_null_life_satisfaction\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_null(housing).index[0]\n",
        "expected = 613 \n",
        "\n",
        "if actual == expected and len(drop_null(housing)) == 352:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 352 but was\", len(drop_null(housing))) "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])` \n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries \n",
        "---\n",
        "Write a function called **drop_duplicates** which will: \n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74",
        "outputId": "be29fee0-a2b0-40b1-dcef-5476da0ed8ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def drop_duplicates(df):\n",
        "  # add code which returns a dataframe without duplicate area entries with first instance kept \n",
        "  housing_drop_duplicates = df.drop_duplicates(subset = ['area'])\n",
        "  return housing_drop_duplicates\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_duplicates(housing).index[0]\n",
        "expected = 0\n",
        "\n",
        "if actual == expected and len(drop_duplicates(housing)) == 51:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 51 but was\", len(drop_duplicates(housing))) "
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQyytEbnZ1lw"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM00hR5aZk1-"
      },
      "source": [
        "Your answer: I have continued to use data retrieval and have learnt to use sorting and cleaning libraries in pandas. I have demonstated how I can identify null values, calculated total null values in the data frame, remove rows with null values for specific columns, remove rows that have duplicate values in a colum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgexd27sZ1ly"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y_nrVBwaGXr"
      },
      "source": [
        "Your answer: This worksheet was fairly easy, now that I have an idea of what I am doing with panda libraries. I did not encounter have too many problems (only typo errors!)."
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Wrangle-the-data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaySanthanam/Programming-for-data/blob/main/Worksheets/4_Wrangle_the_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKBQIxC4YPKX"
      },
      "source": [
        "# Merging dataframes, creating new columns, replacing with default or correctly formatted values\n",
        "---\n",
        "\n",
        "## Merging dataframes\n",
        "\n",
        "We often want to use data from a set of different data files, or a set of dataframes we have prepared, to combine into one dataframe.\n",
        "\n",
        "### To merge two dataframes together when both dataframes have column headings in common - stacking them one on top of another \n",
        "\n",
        "If `df1` and `df2` have some column headings in common, to combine the two into one dataframe we use:  \n",
        "\n",
        "`pd.concat([dataframes to combine])`\n",
        "\n",
        "This will create a new dataframe with all columns from the original two dataframes, which we can store in a new variable for later use.  Missing values are filled with null values. \n",
        "\n",
        "If we want only the column headings that appear in both tables, we can use join='inner':\n",
        "\n",
        "`pd.concat([dataframes to combine], join='inner')` \n",
        "\n",
        "We may also need to refactor the indexing, where two tables are indexed from 0 upwards, adding the two tables together will result in multiple occurences of the same index.  This can be overcome by using ignore_index=True:\n",
        "\n",
        "`pd.concat([dataframes to combine], join='inner', ignore_index=True)`\n",
        "\n",
        "\n",
        "### Merging dataframes by common column matching values\n",
        "\n",
        " `pd.merge(datframe1, dataframe2)`\n",
        "\n",
        " extra parameters: \n",
        " * which columns to merge by when the column name is the same in both dataframes: \n",
        "  * single column `pd.merge(df, df2, on='column_name')`  \n",
        "  * multiple columns `pd.merge(df, df2, on=['column1', 'column2']`\n",
        "\n",
        "* which columns to merge by when columns have different names in each dataframe \n",
        "  * single column `pd.merge(df1, df2, left_on = 'df1_column', right_on = 'df2_column')`\n",
        "  * multiple column `pd.merge(df1, df2, left_on = ['df1_column1', 'df1_column2'], right_on = ['df2_column1', 'df2_column2'])`\n",
        "* what kind of join (inner, left, right or cross) inner is default\n",
        "  * `pd.merge(df1, df2, how = '....')`\n",
        "  * inner will join with all columns\n",
        "  * left joins with just first stated df columns \n",
        "  * right joins with just second stated df columns\n",
        "  * cross is a mix of both\n",
        "\n",
        "* To specify only specific columns to be returned from each dataframe\n",
        "  * `pd.merge(df1[['column1', 'column2']], df2[['column1', 'column2', 'column3']], on = ['column1', 'column2'])\n",
        "  * you must include the columns from each dataframe that are being merged on\n",
        "\n",
        "\n",
        "\n",
        "### Difference between concat and merge: \n",
        "\n",
        "```\n",
        "df1:  \n",
        "          Key  data1\n",
        "      0   b   0\n",
        "      1   b   1\n",
        "      2   a   2\n",
        "      3   c   3\n",
        "      4   a   4\n",
        "      5   a   5\n",
        "      6   b   6\n",
        "\n",
        "df2:\n",
        "    Key data2\n",
        "0   a   0\n",
        "1   b   1\n",
        "2   d   2\n",
        "\n",
        "# merge would look like this:\n",
        "\n",
        "pd.merge(df1, df2)\n",
        "\n",
        "   Key data1 data2\n",
        "0   b    0    1\n",
        "1   b    1    1\n",
        "2   b    6    1\n",
        "3   a    2    0\n",
        "4   a    4    0\n",
        "5   a    5    0\n",
        "\n",
        "# concat would look like this\n",
        "\n",
        "pd.concat([df1, df2])\n",
        "\n",
        "   Key data1 data2\n",
        "0   b   0     NaN\n",
        "1   b   1     NaN\n",
        "2   a   2     NaN\n",
        "3   c   3     NaN\n",
        "4   a   4     NaN\n",
        "5   a   5     NaN\n",
        "6   b   6     NaN\n",
        "0   a   Nan   0\n",
        "1   b   Nan   1\n",
        "2   d   Nan   2\n",
        "```\n",
        "\n",
        "Merge is particularly useful with datasets that share a unique index eg. two datasets that were indexed by date or country \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0mUEA5ugGyJ"
      },
      "source": [
        "### Exercise 1 - combine the two data sets\n",
        "\n",
        "The Excel file at this URL https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/Income-Data.xlsx?raw=true contains TWO data sheets named county-level and state-level.  \n",
        "\n",
        "Read the county-level sheet into a dataframe called **county_level_df** \n",
        "Read the state-level sheet into a dataframe called **state_level_df** \n",
        "\n",
        "Write a function called **combine_whole** which: \n",
        "\n",
        "Uses `pd.concat([list of dataframes])` to combine the two dataframes into a new dataframe called **income_df**, filling missing values with null values.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6qHNDn-YN0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d675b89d-76b0-4f67-a0b9-4da90c01be38"
      },
      "source": [
        "def combine_whole(df1, df2):\n",
        "  # add code to combine the 2 dataframes, filling missing values with NA\n",
        "  combine_df = pd.concat([df1, df2])\n",
        "  return combine_df\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "url = \"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/Income-Data.xlsx?raw=true\"\n",
        "county_level_df = pd.read_excel(url,sheet_name=\"county-level\") \n",
        "state_level_df = pd.read_excel(url,sheet_name=\"state-level\") \n",
        "\n",
        "# create new dataframe from your function above \n",
        "\n",
        "income_df = combine_whole(county_level_df, state_level_df)\n",
        "print(income_df)\n",
        "\n",
        "# This will run and test your code to check your new dataframe contains null values \n",
        "actual = income_df.isnull().values.any()\n",
        "expected = True \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"got\", actual)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   State  County  Population  Age  Income      Pop  Education\n",
            "0     TX     1.0        72.0   34      65      NaN        NaN\n",
            "1     TX     2.0        33.0   42      45      NaN        NaN\n",
            "2     TX     5.0        25.0   23      46      NaN        NaN\n",
            "3     TX     6.0        54.0   36      65      NaN        NaN\n",
            "4     TX     7.0        11.0   42      53      NaN        NaN\n",
            "5     TX     8.0        28.0   25      62      NaN        NaN\n",
            "6     TX     9.0        82.0   35      66      NaN        NaN\n",
            "7     TX    10.0         5.0   40      75      NaN        NaN\n",
            "8     MD    11.0        61.0   27      22      NaN        NaN\n",
            "9     MD     2.0         5.0   23      69      NaN        NaN\n",
            "10    MD     4.0        98.0   25      73      NaN        NaN\n",
            "11    MD     3.0        64.0   29      75      NaN        NaN\n",
            "12    MD     2.0        36.0   24      65      NaN        NaN\n",
            "13    MD     1.0        24.0   25      66      NaN        NaN\n",
            "14    MD     5.0        34.0   31      78      NaN        NaN\n",
            "15    MD     6.0        89.0   22      81      NaN        NaN\n",
            "16    MD     8.0        21.0   25      73      NaN        NaN\n",
            "17    MD     7.0        21.0   30      62      NaN        NaN\n",
            "0     TX     NaN         NaN   32      54  23543.0       10.2\n",
            "1     MD     NaN         NaN   29      69  10343.0       10.3\n",
            "2     IN     NaN         NaN   41      35   5231.0       10.1\n",
            "3     CA     NaN         NaN   35      67  29587.0       10.4\n",
            "4     NY     NaN         NaN   34      78  18142.0       10.2\n",
            "Test passed True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aekH_ewx7FM3"
      },
      "source": [
        "### Exercise 2 - ignoring index to get a new indexing system\n",
        "---\n",
        "\n",
        "All rows in each dataframe are indexed from 0 to one less than the number of rows.  You may have noticed that the concatenation in the previous exercise has kept the indexing from the individual tables.  \n",
        "\n",
        "If we are making a new table it may make sense to create a new set of indices, from 0 to one less than the length of the new table.   Do this by adding an extra paramater ignore_index=True.  ignore_index is False by default and all original indices are kept.\n",
        "\n",
        "We can also use `join='inner'` to only join columns which are common to both tables\n",
        "\n",
        "Write a function called **combine_common** which will: \n",
        "\n",
        "Combine the dataframes `county_level_df` and `state_level_df` into a new dataframe called `income_df`, adding the parameter `ignore_index=True` and join via inner join. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ABjwed8Rpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9989d145-2a40-488d-f1d2-6ae1ba1cec86"
      },
      "source": [
        "def combine_common(df1,df2):\n",
        "  # add code to combine the 2 dataframes ignoring index and using inner join\n",
        "  combine_income_df = pd.concat([df1, df2], join='inner', ignore_index=True)\n",
        "  return combine_income_df\n",
        "\n",
        "# create new dataframe from your function above \n",
        "income_df = combine_common(county_level_df, state_level_df)\n",
        "\n",
        "# This will run and test your code to check your new dataframe ends with the correct index and has the right number of columns \n",
        "actual = income_df.index[-1]\n",
        "print(income_df)\n",
        "expected = 22\n",
        "\n",
        "if actual == expected and len(income_df.columns) == 3:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected last row index of\", expected, \"got\", actual, \"and expected 3 columns but got\", len(income_df.columns))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   State  Age  Income\n",
            "0     TX   34      65\n",
            "1     TX   42      45\n",
            "2     TX   23      46\n",
            "3     TX   36      65\n",
            "4     TX   42      53\n",
            "5     TX   25      62\n",
            "6     TX   35      66\n",
            "7     TX   40      75\n",
            "8     MD   27      22\n",
            "9     MD   23      69\n",
            "10    MD   25      73\n",
            "11    MD   29      75\n",
            "12    MD   24      65\n",
            "13    MD   25      66\n",
            "14    MD   31      78\n",
            "15    MD   22      81\n",
            "16    MD   25      73\n",
            "17    MD   30      62\n",
            "18    TX   32      54\n",
            "19    MD   29      69\n",
            "20    IN   41      35\n",
            "21    CA   35      67\n",
            "22    NY   34      78\n",
            "Test passed 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QAJS3TJCz_p"
      },
      "source": [
        "# Appending rows to a dataframe\n",
        "\n",
        "Where two dataframes have matching columns, we can append one to the other to add the records from one onto the end of the other.\n",
        "\n",
        "We do this using dataframe.append()\n",
        "\n",
        "`income_2 = income.append()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwarv13blWyg"
      },
      "source": [
        "### Exercise 3 - add new rows to the end of the income dataframe\n",
        "\n",
        "The sheet `income` in the Excel data file has 10 further records showing State, Age and Income only, so this table matches the income dataframe exactly.\n",
        "\n",
        "Read the data from sheet_name `income` in the same Excel data file into a new dataframe called **income_new**.  \n",
        " \n",
        "Write a function called **combine_income** which will: \n",
        "\n",
        "Append this dataframe to the `income_df` dataframe to form a new dataframe called **income_df_v2**.  Use the ignore_index=True parameter to reindex.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exik-fYQ_ORy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73fc1a21-4f88-4af3-d85f-6e56158952f4"
      },
      "source": [
        "def combine_income(df1, df2):\n",
        "  # add code below to join the income_new dataframe with the income_df dataframe ignoring the index\n",
        "  income_2 = df1.append(df2,ignore_index=True)\n",
        "  return income_2\n",
        " \n",
        "\n",
        "income_new = pd.read_excel(url,sheet_name=\"income\")\n",
        "# save returned dataframe in a variable\n",
        "income_df_v2 = combine_income(income_new,income_df)\n",
        "\n",
        "# This will run and test your code to see if new dataframe has correct number of columns and correct indexing \n",
        "actual = income_df_v2.index[-1]\n",
        "expected = 32\n",
        "print(income_df_v2)\n",
        "if actual == expected and len(income_df_v2.columns) == 4:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected last row index of\", expected, \"got\", actual, \"and expected 4 columns but got\", len(income_df_v2.columns))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   State  Age  Income   Pop\n",
            "0     TX   32      69  70.0\n",
            "1     MD   41      35  33.0\n",
            "2     IN   32      69  23.0\n",
            "3     CA   35      54  54.0\n",
            "4     NY   29      78  11.0\n",
            "5     TX   35      54  27.0\n",
            "6     MD   34      67  81.0\n",
            "7     IN   41      35  24.0\n",
            "8     CA   29      78  10.0\n",
            "9     NY   34      67   7.0\n",
            "10    TX   34      65   NaN\n",
            "11    TX   42      45   NaN\n",
            "12    TX   23      46   NaN\n",
            "13    TX   36      65   NaN\n",
            "14    TX   42      53   NaN\n",
            "15    TX   25      62   NaN\n",
            "16    TX   35      66   NaN\n",
            "17    TX   40      75   NaN\n",
            "18    MD   27      22   NaN\n",
            "19    MD   23      69   NaN\n",
            "20    MD   25      73   NaN\n",
            "21    MD   29      75   NaN\n",
            "22    MD   24      65   NaN\n",
            "23    MD   25      66   NaN\n",
            "24    MD   31      78   NaN\n",
            "25    MD   22      81   NaN\n",
            "26    MD   25      73   NaN\n",
            "27    MD   30      62   NaN\n",
            "28    TX   32      54   NaN\n",
            "29    MD   29      69   NaN\n",
            "30    IN   41      35   NaN\n",
            "31    CA   35      67   NaN\n",
            "32    NY   34      78   NaN\n",
            "Test passed 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6W6V8P9Eo2A"
      },
      "source": [
        "### Exercise 4 - Create a new Pop column in county_level_df\n",
        "\n",
        "Looking at the tables country_level_df and state_level_df, each has a column containing data on population.  One column is headed *Population* and the other is headed *Pop*.  Ideally these would be merged into one column and this would minimise the number of NaN entries.  \n",
        "\n",
        "Write a function called **create_pop** that:\n",
        "\n",
        "*  Add a new column called '`Pop`' to the `county_level_df` dataframe which contains a copy of all the values in the '`Population`' column  (`df['new_name'] = df['existing_name']`)  \n",
        "*  Drop the 'Population' column `df.drop([column name], axis=1)` from `county_level_df` and store the result in a new dataframe called **county_level_df_v2**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb_FWSLbG_zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd46bb8d-c18a-47f7-cb4c-7334e49ce351"
      },
      "source": [
        "def create_pop(df):\n",
        "  # add code below to join the income_new dataframe with the income_df dataframe ignoring the index\n",
        "  df['Pop'] = df['Population']\n",
        "  df = df.drop(['Population'],axis=1)\n",
        "  return df\n",
        "\n",
        "# save returned dataframe in a variable\n",
        "county_level_df_v2 = create_pop(county_level_df)\n",
        "\n",
        "# This will run and test your code to see if new dataframe contains pop column and dropped population column \n",
        "if 'Pop' in county_level_df_v2.columns and len(county_level_df_v2.columns) == 5:\n",
        "  print(\"Test passed, contains 5 columns including Pop column\")\n",
        "elif 'Pop' in county_level_df_v2.columns and len(county_level_df_v2.columns) != 5:\n",
        "  print(\"Test not passed, expected 5 columns, instead got\", len(county_level_df_v2.columns))\n",
        "else: \n",
        "  print(\"Test not passed, column Pop not present\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed, contains 5 columns including Pop column\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ku407dEU_3"
      },
      "source": [
        "## Exercise 5 - clean up the format of the Pop column in state_level_df\n",
        "\n",
        "Now that both dataframes hava a Pop column, we should make the data consisent in format for both dataframes.\n",
        "\n",
        "In `state_level_df` the values in the `Pop` column are in 1000s.  In `county_level_df_v2` the values in the `Pop` column are actual numbers.  Let's convert the `state_level_df` values from 1000s for consistency.  We can do this by performing an operation on a column ( `df[column name] = df[column name] // 1000 `) \n",
        "\n",
        "first copy the state_level_df into a new variable called **state_level_df_copy** you can do this like: `df_new = df.copy()` \n",
        "\n",
        "Write a function called **clean_pop** which will:\n",
        "\n",
        "*  convert the values in the `Pop` column of the `state_level_df` dataframe from numbers of 1000s to actual numbers, rounding to whole numbers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5xM8g68N-wY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc36c47c-7d08-417f-c582-1b3c154ed6e6"
      },
      "source": [
        "state_level_df = pd.read_excel(\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/Income-Data.xlsx?raw=true\", sheet_name = 'state-level')\n",
        "state_level_df_copy = state_level_df.copy()\n",
        "\n",
        "def clean_pop(df):\n",
        "  #add code below which converts the Pop column to actual numbers rather than 1000s \n",
        "  df[\"Pop\"] = df[\"Pop\"] // 1000\n",
        "  return df\n",
        "  \n",
        "\n",
        "# create new variable \n",
        "state_level_df_v2 = clean_pop(state_level_df)\n",
        "\n",
        "\n",
        "# This will run and test your code to see if you've correctly converted the column to 10s instead of 1000s\n",
        "actual = state_level_df_v2['Pop'].max()\n",
        "expected = 29\n",
        "\n",
        "if actual == expected and len(income_df_v2.columns) == 4:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed, expected max of\", expected, \"got\", actual)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRoghwoOilff"
      },
      "source": [
        "### Exercise 6 - combine the two v2 dataframes using concat\n",
        "\n",
        "Write function **combine_v2** which will: \n",
        "\n",
        "Combine `county_level_df_v2` and `state_level_df_v2` to create a new dataframe called **income_df_v3**.  The join type should be 'inner' and ignore_index should be True\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbSGRddLJXO3"
      },
      "source": [
        "def combine_v2():\n",
        "  # return the 2 dataframes combined joined inner and ignoring index \n",
        "  \n",
        "\n",
        "# save within a new dataframe\n",
        "\n",
        "\n",
        "# This will run and test your code to see if your new dataframe is correct length and has correct number of columns \n",
        "\n",
        "actual = len(income_df_v3)\n",
        "actual2 = len(income_df_v3.columns)\n",
        "expected = 23 \n",
        "expected2 = 4 \n",
        "\n",
        "if actual == expected and actual2 == expected2:\n",
        "  print(\"Test passed\", actual, \"rows and 4 columns\")\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"rows\", expected2, \"columns but got\", actual, \"rows and\", actual2,\"columns\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXvA-Va2d3QM"
      },
      "source": [
        "### Exercise 7 - Combining dataframes using merge \n",
        "---\n",
        "read in 2 new dataframes called **skill_df** and **industry_df** using the 'Skill Migration' sheet and 'Industry Migration' sheet from the following excel spreadsheet:\n",
        "\"https://github.com/futureCodersSE/working-with-data/blob/main/Data%20sets/public_use-talent-migration.xlsx?raw=true\"\n",
        "\n",
        "Write a function called `get_combine()` which will: \n",
        "\n",
        "Use the merge() function to combine the industry and skill migration dataframes, merging on the country column and the skill group column (industry_name in industry sheet). Only keep the two merge columns and 'wb_income' and 'net_per_10k_2019' columns when merging to create a new dataframe called `migration_df`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC2b4eBhi3-v",
        "outputId": "fc8dcf40-8aee-4bee-afc2-5d2a35d55d9d"
      },
      "source": [
        "def get_combine():\n",
        "  # merge dataframes into variable called migration_df and return it \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return migration_df\n",
        "\n",
        "# This will run and test your code to see if your new dataframe is correct length and has correct number of columns \n",
        "\n",
        "actual = len(get_combine())\n",
        "actual2 = len(get_combine().columns)\n",
        "expected = 873 \n",
        "expected2 = 6\n",
        "\n",
        "if actual == expected and actual2 == expected2:\n",
        "  print(\"Test passed\", actual, \"rows\", actual2, \"columns\")\n",
        "else:\n",
        "  print(\"Test failed, expected\", expected, \"rows\", expected2, \"columns but got\", actual, \"rows and\", actual2,\"columns\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test passed 873 rows 6 columns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZOHWyPOHkmy"
      },
      "source": [
        "### Exercise 8 - pivot table of state and population \n",
        "---\n",
        "\n",
        "Write a function called **create_pivot** which will:\n",
        "\n",
        "Create a pivot table of `Pop` by `State` and store the result in a new dataframe called **population_pivot**  using `income_df_v3` created in exercise 6\n",
        "\n",
        "To make a pivot table:\n",
        "\n",
        "`df_pivot = pd.pivot_table(\n",
        "      df, \n",
        "      values = 'column1 name',\n",
        "      index = 'column2 name', \n",
        "      columns = 'column3 name',\n",
        "      aggfunc = np.mean\n",
        ")`  \n",
        "If index column is not specified, it will automatically use the existing dataframe index   \n",
        "Make sure to `import numpy as np` if you want to aggregate the means using `aggfunc`. \n",
        "\n",
        "**Test Input**  \n",
        "population_pivot.shape   \n",
        "**Test Output**  \n",
        "(1, 5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZC9EuabJIGi"
      },
      "source": [
        "\n",
        "def create_pivot(df):\n",
        "  #add code below which creates a pivot table of Pop and State \n",
        "  \n",
        "  return df_pivot\n",
        "\n",
        "\n",
        "\n",
        "#save series in a new variable\n",
        "population_pivot = create_pivot(income_df_v3)\n",
        "\n",
        "\n",
        "# This will run and test your code to see if your new series is the correct length\n",
        "actual = len(population_pivot)\n",
        "expected = 5 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed expected\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQyytEbnZ1lw"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM00hR5aZk1-"
      },
      "source": [
        "Your answer: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgexd27sZ1ly"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y_nrVBwaGXr"
      },
      "source": [
        "Your answer: "
      ]
    }
  ]
}
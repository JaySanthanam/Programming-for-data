{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaySanthanam/Programming-for-data/blob/main/Worksheets/12_WatsonToneAnalyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyS2Fb7jTftO"
      },
      "source": [
        "# Mini-project - creating a dataframe from analysed text data\n",
        "\n",
        "For this project you are going to use the IBM Watson Tone Analyser API.  You will send text data to it, use security information stored in a config file to keep it secret, receive the results in JSON format, investigate the structure of the results and build a dataframe from them.\n",
        "\n",
        "Then you will use the results to create a visualisation of tone and to report an overall set of statistics from the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsZ4_b2rTftU"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 1 - sign up for IBM Watson services to use the Tone Analyser\n",
        "\n",
        "1.  Sign up for [IBM Watson](https://cloud.ibm.com/registration?cm_mmc=dw-_-cognitive-_-topcoder-_-communityEducational1)\n",
        "2.  Click 'Try on Cloud at no cost'  \n",
        "3.  Select the London region  (costs reduced and performance improved when you use the nearest servers)  \n",
        "4.  Create an IBM Cloud account (enter email and accept terms)  \n",
        "5.  Follow the instructions to create the account  \n",
        "6.  Provision the services  \n",
        "7.  Then go to IBM Watson Studio  \n",
        "8.  Select Tone Analyzer under the Your Services heading  \n",
        "9.  You will be shown the **url** for the Tone Analyser API and an **API key** which is needed for using the API."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - add security to your worksheet to keep your apikey and url hidden\n",
        "\n",
        "You can do this by using environment variables, which are stored in the operating system for this worksheet.\n",
        "\n",
        "We will use a simplified system for storing the sensitive data so that it isn't visible in the worksheet:\n",
        "\n",
        "1.  Ask for the api key to be input and store it in an environment variable called apikey\n",
        "\n",
        "2.  Ask for the url to be input and store it in an environment variable\n",
        "\n",
        "3.  Run the cell, type in the api key, then the url.  Once tis has been done.  Remove the output part of the cell."
      ],
      "metadata": {
        "id": "ZV19Vcgp2JHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# add the code to ask for the URL, then run this cell and when it has completed, remove the output (note: you will need to do this again if you return to the worksheet)\n",
        "os.environ['APIKEY'] = input(\"Enter API key: \")\n",
        "os.environ['URL'] = input(\"Enter URL: \")\n"
      ],
      "metadata": {
        "id": "ZM4PRCOZ2zyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install the ibm_watson libraries so that you can use their functions"
      ],
      "metadata": {
        "id": "fOKQWCOw1AGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install the ibm_watson libraries\n",
        "\n",
        "!pip install ibm_watson"
      ],
      "metadata": {
        "id": "Uhi1cWMwQrZy",
        "outputId": "ae4ea46d-c7a4-4346-8c3d-309954ce4d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ibm_watson\n",
            "  Downloading ibm-watson-5.3.1.tar.gz (413 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 18.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 16.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 92 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 112 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 122 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 133 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 163 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 174 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 184 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 204 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 215 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 225 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 235 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 245 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 256 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 266 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 276 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 286 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 296 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 307 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 317 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 327 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 337 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 348 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 358 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 368 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 378 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 389 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 399 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 409 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 413 kB 18.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ibm-cloud-sdk-core==3.*,>=3.3.6\n",
            "  Downloading ibm-cloud-sdk-core-3.14.0.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.8.2)\n",
            "Requirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from ibm_watson) (2.23.0)\n",
            "Collecting websocket-client==1.1.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.4 MB/s \n",
            "\u001b[?25hCollecting requests<3.0,>=2.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting urllib3<2.0.0,>=1.26.0\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 54.2 MB/s \n",
            "\u001b[?25hCollecting PyJWT<3.0.0,>=2.0.1\n",
            "  Downloading PyJWT-2.3.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.3->ibm_watson) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n",
            "Building wheels for collected packages: ibm-watson, ibm-cloud-sdk-core\n",
            "  Building wheel for ibm-watson (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-watson: filename=ibm_watson-5.3.1-py3-none-any.whl size=409192 sha256=4678dc72bb009598abee540e47b9e967699f9d2cc223458e56547c5c263fb1dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/37/94/3d98f00e5be5dc05434c93028f36ae7ff06705f7939f04797b\n",
            "  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-3.14.0-py3-none-any.whl size=83275 sha256=d9d1a353c07a8f41f7a7875db1d062522ddc1a9fa5aaedd2a4c52d2b622c0bb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/d3/a0/fa4679c34222e203548311390d6baefe8c0e8fddadde1efa73\n",
            "Successfully built ibm-watson ibm-cloud-sdk-core\n",
            "Installing collected packages: urllib3, requests, PyJWT, websocket-client, ibm-cloud-sdk-core, ibm-watson\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed PyJWT-2.3.0 ibm-cloud-sdk-core-3.14.0 ibm-watson-5.3.1 requests-2.27.1 urllib3-1.26.8 websocket-client-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqs2PZBXTftW"
      },
      "source": [
        "---\n",
        "\n",
        "## Test to make sure it works\n",
        "\n",
        "1.  Open this file, which has some text for you to test with: https://drive.google.com/file/d/1m65cPQGYQd1mwvEmfZw69-GMUBdo43k0/view?usp=sharing.  You will be able to copy and paste the text into here as needed.\n",
        "\n",
        "2.  Get the environment variable for each of the two pieces of security information so that these do not need to be included in your notebook (have the keys available for copying and pasting).  To do this:\n",
        "\n",
        "  ``` apikey = os.environ.get('APIKEY') ```\n",
        "\n",
        "3.  Run the code below,which will create a ToneAnalyzer with the credentials from your environment variables, then paste the text from the **text-for-analysis.txt** file\n",
        "\n",
        "4.  Decide what the data looks like and how this might be represented in a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f_zyVYfTftY"
      },
      "outputs": [],
      "source": [
        "from ibm_watson import ToneAnalyzerV3\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "import os\n",
        "import json\n",
        "\n",
        "# get credentials from the environment variables you set\n",
        "def get_secret(key):\n",
        "    # add code here to get the keys from the environment variable and return the requested key\n",
        "    # if there is an error print an error message and return None\n",
        "    return os.environ.get(key)\n",
        "\n",
        "\n",
        "    \n",
        "def get_text_for_analysis():\n",
        "    # add code here to input the text from the text-for-analysis.txt file and return the text it reads as one string\n",
        "    # if there is an error, return None\n",
        "    # return 'Team, I know that times are tough! Product sales have been disappointing for the past three quarters. We have a competitive product, but we need to do a better job of selling it!'\n",
        "    return 'But I feel peaceful. Your success in the ring this morning was, to a small degree, my success. Your future is assured. You will live, secure and safe, Wilbur. Nothing can harm you now. These autumn days will shorten and grow cold. The leaves will shake loose from the trees and fall. Christmas will come, and the snows of winter. You will live to enjoy the beauty of the frozen world, for you mean a great deal to Zuckerman and he will not harm you, ever. Winter will pass, the days will lengthen, the ice will melt in the pasture pond. The song sparrow will return and sing, the frogs will awake, the warm wind will blow again. All these sights and sounds and smells will be yours to enjoy, Wilbur-this lovely world, these precious days.'\n",
        "     \n",
        "    \n",
        "# create a ToneAnalyzerV3 object, version 2017-09-21 using api key and url from config\n",
        "authenticator = IAMAuthenticator(apikey=get_secret('APIKEY'))\n",
        "tone_analyzer = ToneAnalyzerV3(\n",
        "    version='2017-09-21',\n",
        "    authenticator=authenticator\n",
        ")\n",
        "tone_analyzer.set_service_url(get_secret('URL'))\n",
        "\n",
        "# get the text for analysis from the file\n",
        "text = get_text_for_analysis()\n",
        "if text:\n",
        "    tone_analysis = tone_analyzer.tone(\n",
        "        {'text': text},\n",
        "        content_type='application/json'\n",
        "    ).get_result()    \n",
        "    print(tone_analysis)\n",
        "else:\n",
        "    print(\"No data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WORKING WITH THE OUTPUT OF TEXT ANALYSIS"
      ],
      "metadata": {
        "id": "6faYfT24rI7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Watson Tone Analyser API Output\n",
        "---\n",
        "\n",
        "This is the output that the given text will produce. You will need to assign this output to a variable called **tone_analysis** in the function you are going to write below. \n",
        "\n",
        "```\n",
        "{'document_tone': {'tones': [{'score': 0.582191, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.829888, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, 'sentences_tone': [{'sentence_id': 0, 'text': 'Team, I know that times are tough!', 'tones': [{'score': 0.801827, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 1, 'text': 'Product sales have been disappointing for the past three quarters.', 'tones': [{'score': 0.817406, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.687768, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 2, 'text': 'We have a competitive product, but we need to do a better job of selling it!', 'tones': [{'score': 0.506763, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}]}\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9hjqn6lrd4RE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tone_analysis = {'document_tone': {'tones': [{'score': 0.582191, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.829888, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, 'sentences_tone': [{'sentence_id': 0, 'text': 'Team, I know that times are tough!', 'tones': [{'score': 0.801827, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 1, 'text': 'Product sales have been disappointing for the past three quarters.', 'tones': [{'score': 0.817406, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.687768, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 2, 'text': 'We have a competitive product, but we need to do a better job of selling it!', 'tones': [{'score': 0.506763, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}]}"
      ],
      "metadata": {
        "id": "BCKdlM0ZAKDz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMHlV6wpTftb"
      },
      "source": [
        "### Create (on paper) an idea of how this data might be organised into a data table\n",
        "\n",
        "1.  How many bits of information are there about the document as a whole?\n",
        "2.  How many bits of information are there about each sentence?\n",
        "3.  If all tone analysis records were included in the dataframe, how many rows would there be?\n",
        "4.  What information would be included in each row?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. There are 2 document tones and 3 sentence tones, marked by sentence_id from 0-2. However, sentence id 1 has 2 scores associated with it.\n",
        "\n",
        "2. Each sentence has tones that have the following keys:\n",
        "*   text\n",
        "*   score\n",
        "*   tone_id\n",
        "*   tone_name\n",
        "\n",
        "3. There are 3 sentence rows (one for each id) and 2 rows for document tone.\n",
        "\n",
        "4. In each row we will have the score, tone_id and tone_name.\n",
        "\n"
      ],
      "metadata": {
        "id": "UOZRzdaeJo5N"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ-p60NeTftc"
      },
      "source": [
        "### Create a dataframe and start to populate with the data\n",
        "\n",
        "You can create a **dataframe** from this data either by converting it manually into a table OR by using the pandas function pd.json_normalise(data).  \n",
        "\n",
        "**Manually**:\n",
        "\n",
        "One way to do this would be to create a list of dictionary records, with each record formed from the data from each row in the original 'sentences_tone' data.  You will need to loop through the rows in the 'sentences_tone' list, nesting a loop through the 'tones' list for each sentence.  For each, copy across the columns you feel should be included.\n",
        "\n",
        "_Hint:_  \n",
        "```\n",
        " for row in sentence_data:\n",
        "        for col in row['tones']:\n",
        "            new_row = {'sentence_id':row['sentence_id'], 'text':row['text'], 'tone_score':col['score'], 'tone_id':col['tone_id'],'tone_name':col['tone_name']}\n",
        "```\n",
        "**Using pandas**:\n",
        "\n",
        "An alternative way to do this would be to create a pandas dataframe from the sentences_tone data list (using `pd.json_normalise(data)`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "thFgfS13Tftc",
        "outputId": "d1714886-60f0-46f9-e548-a90e05e3efb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                      sentences_tone                                document_tone.tones\n",
            "0  [{'sentence_id': 0, 'text': 'Team, I know that...  [{'score': 0.582191, 'tone_id': 'sadness', 'to...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import json\n",
        "\n",
        "# convert json data to a dataframe with one row for each tone for each sentence\n",
        "def convert_to_tones_table(data):\n",
        "    # return the data normalized into a dataframe (pd.json_normalise(data))\n",
        "    # the dataframe should have the columns: sentence_id, text, score, tone_id, tone_name\n",
        "    df = pd.json_normalize(data)\n",
        "    return df\n",
        "\n",
        "\n",
        "tone_analysis = {'document_tone': {'tones': [{'score': 0.582191, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.829888, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]},'sentences_tone': [{'sentence_id': 0, 'text': 'Team, I know that times are tough!', 'tones': [{'score': 0.801827, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 1, 'text': 'Product sales have been disappointing for the past three quarters.', 'tones': [{'score': 0.817406, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.687768, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}, {'sentence_id': 2, 'text': 'We have a competitive product, but we need to do a better job of selling it!', 'tones': [{'score': 0.506763, 'tone_id': 'analytical', 'tone_name': 'Analytical'}]}]}\n",
        "tone_data = convert_to_tones_table(tone_analysis)\n",
        "#print(tone_data)\n",
        "\n",
        "tone_df = pd.DataFrame.from_dict(tone_data)\n",
        "print(tone_df)\n",
        "#print(len(tone_df.columns))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LBNPm67Tfte"
      },
      "source": [
        "### Summarise the sentence data\n",
        "*  Which sentence is the most analytical?\n",
        "*  which sentence is the least analytical?\n",
        "*  what is the average analytical tone score for the sentences?\n",
        "*  what do the analytical scores look like in a bar chart?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9QNeA6gTftf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5QvI5ilTftf"
      },
      "source": [
        "### Challenging:  Report the tone data for the whole document\n",
        "---\n",
        "\n",
        "Play with the data, create a dataframe for the document_tone, tones data\n",
        "\n",
        " ```pd.json_normalize(document_tone)```  \n",
        "\n",
        "Display the document score for each of the tones in the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ZY8_msgUTftg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0KZ9z-QTfth"
      },
      "source": [
        "### Change the text in the text file and analyse the new text.\n",
        "---\n",
        "\n",
        "Here is some alternative, happier text.  Replace the text in the text-for-analysis.txt file with the text below.  Then run the notebook cells again to see the results.\n",
        "\n",
        "But I feel peaceful. Your success in the ring this morning was, to a small degree, my success. Your future is assured. You will live, secure and safe, Wilbur. Nothing can harm you now. These autumn days will shorten and grow cold. The leaves will shake loose from the trees and fall. Christmas will come, and the snows of winter. You will live to enjoy the beauty of the frozen world, for you mean a great deal to Zuckerman and he will not harm you, ever. Winter will pass, the days will lengthen, the ice will melt in the pasture pond. The song sparrow will return and sing, the frogs will awake, the warm wind will blow again. All these sights and sounds and smells will be yours to enjoy, Wilbur-this lovely world, these precious days.\n",
        "\n",
        "### The result of this analysis is below:\n",
        "\n",
        "```\n",
        "{'document_tone': {'tones': [{'score': 0.525587, 'tone_id': 'sadness', 'tone_name': 'Sadness'}, {'score': 0.670614, 'tone_id': 'joy', 'tone_name': 'Joy'}, {'score': 0.802229, 'tone_id': 'confident', 'tone_name': 'Confident'}]}, 'sentences_tone': [{'sentence_id': 0, 'text': 'But I feel peaceful.', 'tones': [{'score': 0.511185, 'tone_id': 'joy', 'tone_name': 'Joy'}, {'score': 0.88939, 'tone_id': 'tentative', 'tone_name': 'Tentative'}]}, {'sentence_id': 1, 'text': 'Your success in the ring this morning was, to a small degree, my success.', 'tones': [{'score': 0.919911, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 2, 'text': 'Your future is assured.', 'tones': [{'score': 0.97759, 'tone_id': 'confident', 'tone_name': 'Confident'}]}, {'sentence_id': 3, 'text': 'You will live, secure and safe, Wilbur.', 'tones': [{'score': 0.801827, 'tone_id': 'analytical', 'tone_name': 'Analytical'}, {'score': 0.92125, 'tone_id': 'confident', 'tone_name': 'Confident'}]}, {'sentence_id': 4, 'text': 'Nothing can harm you now.', 'tones': []}, {'sentence_id': 5, 'text': 'These autumn days will shorten and grow cold.', 'tones': []}, {'sentence_id': 6, 'text': 'The leaves will shake loose from the trees and fall.', 'tones': [{'score': 0.621679, 'tone_id': 'fear', 'tone_name': 'Fear'}]}, {'sentence_id': 7, 'text': 'Christmas will come, and the snows of winter.', 'tones': [{'score': 0.614764, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 8, 'text': 'You will live to enjoy the beauty of the frozen world, for you mean a great deal to Zuckerman and he will not harm you, ever.', 'tones': [{'score': 0.930779, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 9, 'text': 'Winter will pass, the days will lengthen, the ice will melt in the pasture pond.', 'tones': [{'score': 0.654012, 'tone_id': 'sadness', 'tone_name': 'Sadness'}]}, {'sentence_id': 10, 'text': 'The song sparrow will return and sing, the frogs will awake, the warm wind will blow again.', 'tones': [{'score': 0.600542, 'tone_id': 'joy', 'tone_name': 'Joy'}]}, {'sentence_id': 11, 'text': 'All these sights and sounds and smells will be yours to enjoy, Wilbur-this lovely world, these precious days.', 'tones': [{'score': 0.939404, 'tone_id': 'joy', 'tone_name': 'Joy'}, {'score': 0.660207, 'tone_id': 'confident', 'tone_name': 'Confident'}]}]}\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "12. WatsonToneAnalyser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Air quality Analyses.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaySanthanam/Programming-for-data/blob/main/Projects/Work_in_progress/Air_quality_Analyses.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Air Quality data Analyses**\n",
        "\n",
        "This notebook documents my work on Air Quality data analyses using Python. we will be using air-quality measurement, particularly, Nitrogen dioxide levels and Particulate Matter (PM10) data from Chatham roadside and Edinburgh measuring centres and use python to retrieve, wrangle, clean, sort and filter the data, analyse and visualise the data to make conclusions on the air quality levels in these two places. The analyses in this notebook looks at Nitrogen dioxide levels and PM10 in these two places and can be repeated for any other pollutants and/or places.\n",
        "\n",
        "The first part of the notebook documents my work on air quality data on Nitrogen dioxide measurements from Chatham Roadside, Kent Edinburgh Haymarket area and St. Leonard's street.\n",
        "\n",
        "The second part of the notebook documents my work on PM10 from Chatham Roadside and Edinburgh St. Leonard's street."
      ],
      "metadata": {
        "id": "7roA3ccObfnp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##What is Air quality and what data is available on it?\n",
        "####Source: Department for Environment Food and Rural affairs (Defra), UK: https://uk-air.defra.gov.uk/air-pollution/\n",
        "\n",
        "Air pollution can cause both short term and long term effects on health and many people are concerned about pollution in the air that they breathe. \n",
        "\n",
        "These people may include:\n",
        "\n",
        "* People with heart or lung conditions, or other breathing problems, whose health may be affected by air pollution.\n",
        "* Parents, carers and healthcare professionals who look after someone whose health is sensitive to pollution.\n",
        "* People who want to know more about air pollution, its causes, and what they can do to help reduce it.\n",
        "* The scientific community and students, who may need data on air pollution levels, either now or in the past, throughout the UK.\n",
        "\n",
        "Free, detailed, clear and easy to use information on air pollution in the UK is available for all these purposes at UK's Defra, website on air pollution (link above)."
      ],
      "metadata": {
        "id": "BsstcDyddXNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Chatham data \n",
        "\n",
        "In this section of this notebook, we look at the air quality data - that is measured value of nitrogen dioxide levels in the air \n",
        "\n",
        "The following data file contains data collected at a roadside monitoring station.  You can see the data in a spreadsheet here: https://docs.google.com/spreadsheets/d/1XpAvrpuyMsKDO76EZ3kxuddBOu7cZX1Od4uEts14zco/edit?usp=sharing\n",
        "\n",
        "The data contains:\n",
        "* a heading line (Chatham Roadside) which needs to be skipped\n",
        "* dates which are sometimes left- and sometimes right-justified indicating that they are not formatted as dates, rather they are text (so need to be converted to dates)\n",
        "* times which are not all in the same format\n",
        "* Nitrogen Dioxide levels which are, again, text and sometimes contain nodata\n",
        "* Status which is always the same\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8qnlsapq24Df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project - clean, sort and wrangle the data\n",
        "\n",
        "Read the dataset into a dataframe, skipping the first row   \n",
        "Convert dates to date format  \n",
        "Remove rows with nodata in the Nitrogen dioxide column  \n",
        "Convert the Nitrogen dioxide levels values to float type  \n",
        "Sort by Nitrogen dioxide level  \n",
        "Create a new column for 'Weekdays' (use df['Date'].dt.weekday)  \n",
        "Rename the column Nitrogen dioxide level to NO2 Level (V ug/m2)  \n",
        "Remove the Status column  \n",
        "\n",
        "The dataset can be viewed here:  https://drive.google.com/file/d/1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ/view?usp=sharing  and the data accessed here: https://drive.google.com/uc?id=1QSNJ3B1ku8kjXsA_tCBh4fbpDK7wVLAA This is a .csv file  \n",
        "\n",
        "**NOTE:** Some useful references are included at the bottom of this spreadsheet.\n",
        "\n",
        "Use the code cell below to work your code."
      ],
      "metadata": {
        "id": "SSvLiFnp4LjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "def data_clean_wrangle(project_data):\n",
        "  project_data['Date'] =  pd.to_datetime(project_data['Date'], format= \"%d/%m/%Y\")\n",
        "  project_data[\"Nitrogen dioxide\"] = project_data[\"Nitrogen dioxide\"].replace('nodata', np.nan)\n",
        "  project_data = project_data.dropna(subset = [\"Nitrogen dioxide\"])\n",
        "  project_data[\"Nitrogen dioxide\"] = pd.to_numeric(project_data[\"Nitrogen dioxide\"], downcast=\"float\")\n",
        "  project_data_sorted = project_data.sort_values(by=['Nitrogen dioxide'])\n",
        "  project_data_sorted['Weekdays'] = project_data_sorted['Date'].dt.weekday\n",
        "  project_data_sorted = project_data_sorted.rename(columns={\"Nitrogen dioxide\": \"NO2 Level (V ug/m2)\"})\n",
        "  project_data_sorted = project_data_sorted.drop(columns=['Status'])\n",
        "  return project_data_sorted\n",
        "\n",
        "def get_csv_data(url):\n",
        "  data = pd.read_csv(url, skiprows=1)\n",
        "  return data\n",
        "\n",
        "\n",
        "url =  \"https://raw.githubusercontent.com/JaySanthanam/Programming-for-data/main/Datasets/NO2_Edin.csv\"\n",
        "data = get_csv_data(url)\n",
        "#project_data = data_clean_wrangle(data)\n",
        "print(data.shape)\n",
        "print(data.head())\n",
        "print(data.info())\n"
      ],
      "metadata": {
        "id": "txM4TIRUHhsJ",
        "outputId": "dd060c67-45eb-456f-acd0-690e86535fcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(35092, 4)\n",
            "         Date   Time Nitrogen dioxide   Status\n",
            "0  01/03/2017  01:00          No data  V ugm-3\n",
            "1  01/03/2017  02:00          No data  V ugm-3\n",
            "2  01/03/2017  03:00          No data  V ugm-3\n",
            "3  01/03/2017  04:00          No data  V ugm-3\n",
            "4  01/03/2017  05:00          No data  V ugm-3\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35092 entries, 0 to 35091\n",
            "Data columns (total 4 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   Date              35089 non-null  object\n",
            " 1   Time              35088 non-null  object\n",
            " 2   Nitrogen dioxide  35088 non-null  object\n",
            " 3   Status            35088 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Date']"
      ],
      "metadata": {
        "id": "QAOkbvzrE81T",
        "outputId": "042e9b5e-f267-4c31-be7d-a6747ca38d67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        01/03/2017\n",
              "1        01/03/2017\n",
              "2        01/03/2017\n",
              "3        01/03/2017\n",
              "4        01/03/2017\n",
              "            ...    \n",
              "35087         44256\n",
              "35088           NaN\n",
              "35089           NaN\n",
              "35090           NaN\n",
              "35091           End\n",
              "Name: Date, Length: 35092, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expand the dataset and show summary statistics for larger dataset\n",
        "---\n",
        "\n",
        "There is a second data set here covering the year 2021:  https://drive.google.com/uc?id=1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ  \n",
        "\n",
        "Concatenate the two datasets to expand it to 2020 and 2021.  \n",
        "\n",
        "Before you can concatenate the datasets you will need to clean and wrangle the second dataset in the same way as the first.  Use the code cell below.  Give the second dataset a different name. \n",
        "\n",
        "After the datasets have been concatenated, group the data by Weekdays and show summary statistics by day of the week."
      ],
      "metadata": {
        "id": "jnzAnbsmHk4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url =  \"https://drive.google.com/uc?id=1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ\"\n",
        "project_data2 = pd.read_csv(url, skiprows=1)\n",
        "project_data2_sorted = data_clean_wrangle(project_data2)\n",
        "project_data_combined = pd.concat([project_data_sorted,project_data2_sorted], join='inner', ignore_index=True)\n",
        "project_data_combined = project_data_combined.sort_values(by=['Weekdays'])\n",
        "print(project_data_combined.groupby(by=[\"Weekdays\"])[[\"NO2 Level (V ug/m2)\"]].describe())\n",
        "#print(project_data_combined.shape)\n",
        "#print(project_data_combined.head())"
      ],
      "metadata": {
        "id": "Gz4u6trsIQJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a14b7a6e-23f2-49f6-f124-b645f3a690a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         NO2 Level (V ug/m2)             ...                      \n",
            "                       count       mean  ...        75%        max\n",
            "Weekdays                                 ...                      \n",
            "0                     2443.0  14.373540  ...  19.659705  82.596092\n",
            "1                     2427.0  15.659355  ...  21.724490  80.278442\n",
            "2                     2483.0  17.288498  ...  24.675005  73.409401\n",
            "3                     2504.0  15.301346  ...  20.472977  72.000839\n",
            "4                     2515.0  15.776768  ...  22.257344  71.219772\n",
            "5                     2495.0  12.568014  ...  17.242315  62.471668\n",
            "6                     2485.0  10.272859  ...  14.229000  53.096161\n",
            "\n",
            "[7 rows x 8 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpful references\n",
        "---\n",
        "Skipping rows when reading datasets:  \n",
        "https://www.geeksforgeeks.org/how-to-skip-rows-while-reading-csv-file-using-pandas/  \n",
        "\n",
        "Converting strings to dates:  \n",
        "https://www.geeksforgeeks.org/convert-the-column-type-from-string-to-datetime-format-in-pandas-dataframe/\n",
        "\n",
        "Dropping rows where data has a given value:  \n",
        "https://www.datasciencemadesimple.com/drop-delete-rows-conditions-python-pandas/  \n",
        "(see section Drop a row or observation by condition) \n",
        "\n",
        "Convert a column of strings to a column of floats:\n",
        "https://datatofish.com/convert-string-to-float-dataframe/  \n",
        "\n",
        "Create a new column from data converted in an existing column:  \n",
        "https://www.geeksforgeeks.org/create-a-new-column-in-pandas-dataframe-based-on-the-existing-columns/  \n",
        "\n",
        "Rename a column:  \n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html  \n",
        "\n",
        "Remove a column by name:  \n",
        "https://www.kite.com/python/answers/how-to-delete-columns-from-a-pandas-%60dataframe%60-by-column-name-in-python#:~:text=Use%20the%20del%20keyword%20to,the%20name%20column_name%20from%20DataFrame%20.\n"
      ],
      "metadata": {
        "id": "hkj-Ofus_D6_"
      }
    }
  ]
}
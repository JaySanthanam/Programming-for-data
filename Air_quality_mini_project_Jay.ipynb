{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Air quality mini-project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaySanthanam/Programming-for-data/blob/main/Air_quality_mini_project_Jay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clean and wrangle air quality data\n",
        "\n",
        "The following data file contains data collected at a roadside monitoring station.  You can see the data in a spreadsheet here: https://docs.google.com/spreadsheets/d/1XpAvrpuyMsKDO76EZ3kxuddBOu7cZX1Od4uEts14zco/edit?usp=sharing\n",
        "\n",
        "The data contains:\n",
        "* a heading line (Chatham Roadside) which needs to be skipped\n",
        "* dates which are sometimes left- and sometimes right-justified indicating that they are not formatted as dates, rather they are text (so need to be converted to dates)\n",
        "* times which are not all in the same format\n",
        "* Nitrogen Dioxide levels which are, again, text and sometimes contain nodata\n",
        "* Status which is always the same\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8qnlsapq24Df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project - clean, sort and wrangle the data\n",
        "\n",
        "Read the dataset into a dataframe, skipping the first row   \n",
        "Convert dates to date format  \n",
        "Remove rows with nodata in the Nitrogen dioxide column  \n",
        "Convert the Nitrogen dioxide levels values to float type  \n",
        "Sort by Nitrogen dioxide level  \n",
        "Create a new column for 'Weekdays' (use df['Date'].dt.weekday)  \n",
        "Rename the column Nitrogen dioxide level to NO2 Level (V ug/m2)  \n",
        "Remove the Status column  \n",
        "\n",
        "The dataset can be viewed here:  https://drive.google.com/file/d/1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ/view?usp=sharing  and the data accessed here: https://drive.google.com/uc?id=1QSNJ3B1ku8kjXsA_tCBh4fbpDK7wVLAA This is a .csv file  \n",
        "\n",
        "**NOTE:** Some useful references are included at the bottom of this spreadsheet.\n",
        "\n",
        "Use the code cell below to work your code."
      ],
      "metadata": {
        "id": "SSvLiFnp4LjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone\n",
        "url =  \"https://drive.google.com/uc?id=1QSNJ3B1ku8kjXsA_tCBh4fbpDK7wVLAA\"\n",
        "project_data = pd.read_csv(url, skiprows=1)\n",
        "project_data['Date'] =  pd.to_datetime(project_data['Date'], format= \"%d/%m/%Y\")\n",
        "project_data[\"Nitrogen dioxide\"] = project_data[\"Nitrogen dioxide\"].replace('nodata', np.nan)\n",
        "project_data = project_data.dropna(subset = [\"Nitrogen dioxide\"])\n",
        "project_data[\"Nitrogen dioxide\"] = pd.to_numeric(project_data[\"Nitrogen dioxide\"], downcast=\"float\")\n",
        "project_data_sorted = project_data.sort_values(by=['Nitrogen dioxide'])\n",
        "project_data_sorted['Weekdays'] = project_data_sorted['Date'].dt.weekday\n",
        "project_data_sorted = project_data_sorted.rename(columns={\"Nitrogen dioxide\": \"NO2 Level (V ug/m2)\"})\n",
        "project_data_sorted = project_data_sorted.drop(columns=['Status'])\n",
        "print(project_data_sorted.shape)\n",
        "print(project_data_sorted.head())"
      ],
      "metadata": {
        "id": "txM4TIRUHhsJ",
        "outputId": "2f5e55df-1e5a-4ade-869c-2d546999af21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8672, 4)\n",
            "           Date   Time  NO2 Level (V ug/m2)  Weekdays\n",
            "3442 2020-05-23  11:00              0.31041         5\n",
            "5844 2020-08-31  13:00              0.38390         0\n",
            "7684 2020-11-16   5:00              0.40116         0\n",
            "7756 2020-11-19   5:00              0.40229         3\n",
            "3440 2020-05-23   9:00              0.41544         5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Expand the dataset and show summary statistics for larger dataset\n",
        "---\n",
        "\n",
        "There is a second data set here covering the year 2021:  https://drive.google.com/uc?id=1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ  \n",
        "\n",
        "Concatenate the two datasets to expand it to 2020 and 2021.  \n",
        "\n",
        "Before you can concatenate the datasets you will need to clean and wrangle the second dataset in the same way as the first.  Use the code cell below.  Give the second dataset a different name. \n",
        "\n",
        "After the datasets have been concatenated, group the data by Weekdays and show summary statistics by day of the week."
      ],
      "metadata": {
        "id": "jnzAnbsmHk4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timezone\n",
        "url =  \"https://drive.google.com/uc?id=1aYmBf9il2dWA-EROvbYRCZ1rU2t7JwvJ\"\n",
        "project_data2 = pd.read_csv(url, skiprows=1)\n",
        "project_data2['Date'] =  pd.to_datetime(project_data2['Date'], format= \"%d/%m/%Y\")\n",
        "project_data2[\"Nitrogen dioxide\"] = project_data2[\"Nitrogen dioxide\"].replace('nodata', np.nan)\n",
        "project_data2 = project_data2.dropna(subset = [\"Nitrogen dioxide\"])\n",
        "project_data2[\"Nitrogen dioxide\"] = pd.to_numeric(project_data2[\"Nitrogen dioxide\"], downcast=\"float\")\n",
        "project_data2_sorted = project_data2.sort_values(by=['Nitrogen dioxide'])\n",
        "project_data2_sorted['Weekdays'] = project_data2_sorted['Date'].dt.weekday\n",
        "project_data2_sorted = project_data2_sorted.rename(columns={\"Nitrogen dioxide\": \"NO2 Level (V ug/m2)\"})\n",
        "project_data2_sorted = project_data2_sorted.drop(columns=['Status'])\n",
        "project_data_combined = pd.concat([project_data_sorted,project_data2_sorted], join='inner', ignore_index=True)\n",
        "project_data_combined = project_data_combined.sort_values(by=['Weekdays'])\n",
        "print(project_data_combined.shape)\n",
        "print(project_data_combined.head())"
      ],
      "metadata": {
        "id": "Gz4u6trsIQJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d575b84-4b8e-4eca-d19a-7a4252ba734a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(17352, 4)\n",
            "            Date   Time  NO2 Level (V ug/m2)  Weekdays\n",
            "17351 2021-11-29  16:00            82.596092         0\n",
            "11941 2021-03-22  05:00            12.298740         0\n",
            "11935 2021-01-04  18:00            12.277890         0\n",
            "11912 2021-09-13  16:00            12.205600         0\n",
            "11899 2021-05-03  10:00            12.167850         0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpful references\n",
        "---\n",
        "Skipping rows when reading datasets:  \n",
        "https://www.geeksforgeeks.org/how-to-skip-rows-while-reading-csv-file-using-pandas/  \n",
        "\n",
        "Converting strings to dates:  \n",
        "https://www.geeksforgeeks.org/convert-the-column-type-from-string-to-datetime-format-in-pandas-dataframe/\n",
        "\n",
        "Dropping rows where data has a given value:  \n",
        "https://www.datasciencemadesimple.com/drop-delete-rows-conditions-python-pandas/  \n",
        "(see section Drop a row or observation by condition) \n",
        "\n",
        "Convert a column of strings to a column of floats:\n",
        "https://datatofish.com/convert-string-to-float-dataframe/  \n",
        "\n",
        "Create a new column from data converted in an existing column:  \n",
        "https://www.geeksforgeeks.org/create-a-new-column-in-pandas-dataframe-based-on-the-existing-columns/  \n",
        "\n",
        "Rename a column:  \n",
        "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html  \n",
        "\n",
        "Remove a column by name:  \n",
        "https://www.kite.com/python/answers/how-to-delete-columns-from-a-pandas-%60dataframe%60-by-column-name-in-python#:~:text=Use%20the%20del%20keyword%20to,the%20name%20column_name%20from%20DataFrame%20.\n"
      ],
      "metadata": {
        "id": "hkj-Ofus_D6_"
      }
    }
  ]
}